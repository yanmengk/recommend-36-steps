# 推荐系统

[TOC]

## 用知识去对抗技术不平等

- 推荐系统从搜索引擎借鉴了不少技术和思想，比如内容推荐有不少技术来自搜索引擎，由Amazon发扬光大，基于用户（User-based）和基于物品（Item-based）的协同过滤将推荐从推荐系统技术从内容延伸到协同关系，超越了内容本身。

## 第1章 概念篇

![img](https://static001.geekbang.org/resource/image/ea/ae/ea17e1afa2a56d022c6f5021822edaae.jpg)

### 第1讲 你真的需要了解个性化推荐系统吗？

1. 它（推荐系统）能做什么？

- 推荐系统可以把那些最终会在用户（User）和物品（Item）之间产生的连接提前找出来。

2. 它需要什么？

- 推荐系统需要已经存在的连接，从已有的连接去预测未来的连接。

3. 怎么做？

- 预测用户评分和偏好

### 第2讲 个性化推荐系统那些绕不开的经典问题

- 推荐系统的使命是为用户和物品建立连接，建立的方式是提前找出那些隐藏的连接呈现给用户，这是一个预测问题；所以推荐系统的预测问题模式，从达成的连接目标角度区分有两大类：

  - 评分预测
  - 行为预测

  行为预测解决的是推荐系统80%的问题，评分预测解决的是最后那20%的问题。

- 推荐系统的常见顽疾：

  - 冷启动问题
  - 探索与利用问题（Exploit 和 Explore。Exploit意为“开采”，对用户身上已经探明的兴趣加以利用，Explore意为“探索”，探明用户身上还不知道的兴趣。
  - 安全问题

### 第3讲 这些你必须应该具备的思维模式

- 开发一个推荐系统产品有4个关键元素需要特别注意（它们的重要性依次递减）：
  - UI和UE（人机交互设计和用户体验设计）
  - 数据
  - 领域知识
  - 算法

- 目标思维和不确定性思维
  - 抓住目标，不择手段地增长目标
    - 对传统软件来说，他们是信息流通管道，如内容APP，核心是逻辑、因果、分层，追求的是稳定和满足预期，背后的思想强调的是逻辑和因果链条。
    - 对推荐产品而言，追求的是指标的增长，如留存率、新闻阅读时间、电商的GMV等等。
  - 推荐系统追求的是目标的增长，不是一城一池的得失。绝大多数推荐算法是概率算法，因此本身无法保证得到确切结果，只是概率上得到好的效果。学会用概率的眼光去看结果，养成不确定性思维。

## 第2章 原理篇

![up](/home/mkyan/图片/up.jpg)

### 第4讲 画鬼容易画人难：用户画像的”能“和”不能“

- 什么是用户画像？（user profile）

  炫酷的用户画像不一定有用，诸如用标签云的方式绘制一个人的形状，或者在一个人物形象旁边列出若干人口统计学属性，这些很可能没用，因为用户画像应该是给机器看的，而不是给人看的。

  **用户画像是对用户信息的向量化表示**，用户画像不是推荐系统的目的，而是在构建推荐系统的过程中产生的一个关键环节的副产品。

- 通常大型推荐系统一般都分为**召回和排序**两个阶段

  因为全量物品通常数量特别大，无法为一个用户user逐一计算每一个物品item的评分，这时候就需要一个召回阶段，预先筛选一部分物品item，从而降低计算量，**用户画像除了用于最终的评分阶段，还要用在召回。所以，构建用户画像就要以这两个阶段为目的。**

- 用户画像构建的方法

  - 使用原始数据，如人口统计学信息、购买历史、阅读历史等，通常对于用户冷启动等场景非常有用
  - 根据历史数据做统计工作，如从历史行为数据中挖掘出标签，然后在标签唯独做数据统计，用统计结果作为量化结果
  - 用机器学习，学习出人类无法直观理解的稠密向量，如使用潜语义模型构建用户阅读兴趣、使用矩阵分解得到隐因子，使用深度学习模型得到的Embedding向量

### 第5讲 从文本到用户画像有多远

- 文本数据是互联网产品中最常见的信息表达形式，数量多、处理快、存储小，因为文本数据的特殊地位，我们来介绍一些建立用户画像过程中用到的数据挖掘算法。

- 要用物品和用户的文本信息构建出一个基础版本的用户画像大致需要做这些事：

  - 把所有非结构化的文本结构化，去粗取精，保留关键信息
  - 根据用户行为数据把物品的结构化结果传递给用户，与用户自己的结构化信息合并

- 结构化文本

  - 从物品端的文本信息，我们可以利用成熟的NLP算法分析得到信息：
    - 关键词提取：最基础的标签来源，也为其他文本分析提供基础数据，常用TF-IDF和TextRank
    - 实体识别：人物、位置和地点，著作、影视剧、历史事件和热点事件等，常用基于词典的方法结合CRF模型
    - 内容分类：将文本按照分类体系分类，用分类来表达较粗粒度的结构化信息
    - 文本聚类：无监督地将文本划分为多个类簇
    - 主题模型：从大量已有文本中学习主题向量，然后再预测新的文本在各个主题上的概率分布情况无标题文档无标题文档
    - 嵌入：挖掘出字面意思之下的语义信息，并用有限的维度表达出来

- 标签选择

  用户端的文本、物品端的文本结构化之后，得到了诸如标签、主题、词嵌入向量等，接下来如何把物品的结构化信息给用户呢？

  一种简单粗暴的方法是直接把用户产生过行为的物品标签累积在一起，这里我们采取另外一种思路：我们把用户对物品的行为，消费或者没有消费看成是分类问题，用户用实际行动帮我们标注了若干数据，那么挑选出他实际感兴趣的特性就变成了**特征选择问题**。

  - 最常见的特征选择方法：卡方检验和信息增益。

    - 卡方检验

    ![ka](/home/mkyan/图片/ka.jpg)

    - 信息增益

      信息增益是一种有监督的特征选择方法，需要有标注信息。

      卡方检验和信息增益不同之处在于：前者针对每一个行为单独筛选出一套标签出来，后者是全局统一筛选。

### 第6讲 超越标签的内容推荐系统

- 基于内容的推荐系统，标签只是很小一部分。所谓的基于内容推荐，就是一个包装成推荐系统的信息检索系统。基于内容的推荐系统是一个推荐系统的孩童时代。

- 为什么要做好内容推荐？

  - 因为内容数据非常易得，不需要有用户行为数据就能够做出推荐系统的第一版
  - 内容数据尤其是文本，只要深入挖掘，就可以挖掘出一些很有用的信息供推荐系统使用
  - 产品冷启动阶段，没有用户行为，别无选择
  - 新的物品要被推荐出去，首选内容推荐

- 要把基于内容的推荐做好，需要做好”抓、洗、挖、算“四门功课。

  - 抓：持续爬取数据，补充内容源
  - 洗：清洗，过滤无关的数据
  - 挖：深入挖掘
  - 算：匹配用户的兴趣和物品的属性，计算出更合理的相关性

- 基于内容推荐的框架：

  ![q](/home/mkyan/图片/q.jpeg)

  - 内容这一端：内容源经过内容分析，得到结构化的内容库和内容模型，也就是物品画像。
  - 用户这一端：用户看过推荐列表后，会产生用户行为数据，结合物品画像，经过用户分析得到用户画像。
  - 随着内容分析的深入，能抓住的用户群体就越细致，推荐的转化率就越高，用户对产品的好感度也就增加了。
  - 基于内容的推荐，最重要的不是推荐算法，而是内容挖掘和分析。

- 内容推荐算法
  - 对于基于内容的推荐系统，最简单的推荐算法当然是计算相似性即可，用户的画像内容就表示为稀疏的向量，同时内容端也有对应的稀疏向量，两者之间计算余弦相似度，根据相似度对推荐物品排序。
  - 如果想进一步，更好地利用内容中的结构化信息，因为一个直观的认识是：不同字段的重要性不同。
  - 可以借鉴信息检索中相关性计算方法来做推荐匹配的计算：BM25F算法，常用开源搜索引擎Lucene中已实现。

### 第7讲 【近邻推荐】人以群分，你是什么人就看到什么世界

![sm](/home/mkyan/图片/sm.jpg)

- 协同过滤通常分为两类

  - 基于记忆的协同过滤（Memory-based）

    记住每个人消费过什么东西，然后给他推荐相似的东西，或者推荐相似的人消费的东西

  - 基于模型的协同过滤（Model-based）

    从用户物品关系矩阵中去学习一个模型，从而把那些矩阵空白处填满

- 基于用户的协同过滤

  - 先根据历史消费行为帮你找到一群和你口味很相似的用户，然后根据这些和你很相似的用户再消费了什么新的、你没有见过的物品，都可以推荐给你。

  - 其实也是一个给用户聚类的过程，如果量化“口味相似”是关键

  - 核心是用户物品的关系矩阵，具体过程如下：

    - 准备用户向量，从这个矩阵中，理论上可以给每一个用户得到一个向量（用户对商品喜欢，或者不喜欢，标1或者0）
    - 用每一个用户的向量，两两计算用户之间的相似度，设定一个相似度阈值或者设定一个最大数量，为每个用户保留与其最相似的用户。
    - 为每一个用户产生推荐结果（去掉用户自己消费过的物品，剩下的排序输出就是推荐结果）

  - 在实践过程中的注意事项

    - 很多矩阵元素不要存，可以构造稀疏矩阵存储格式

    - 相似度计算：降低相似度计算复杂度的方法有两个：

      - 对向量采样计算，如Spark中的DIMSUM算法，损失一部分精度换取计算简化
      - 向量化计算，使用numpy等实现向量化计算

      还可以采用将相似度计算拆成map reduce任务，或者不用基于用户的协同过滤方法解决。

    - 推荐计算

      - 在得到了用户之间的相似度之后，还要计算推荐分数，显然，为每一个用户计算每一个物品的推荐分数这个代价是不能接受的，可以选择只有相似用户喜欢过的物品需要计算
      - 把计算过程拆成map reduce任务

### 第8讲 【近邻推荐】解密“看了又看”和“买了又买”

- 基于用户的协同过滤方法的缺点

  - 用户数量往往很大，计算吃力
  - 用户口味变化其实很快，兴趣迁移问题用此方法很难反应出来
  - 数据稀疏，用户和用户之间有共同消无标题文档费行为实际上比较少，而且都是一些热门商品，对发现用户兴趣帮助不大

- 基于物品的协同过滤（Item based）

  - 之所以有效是因为：

    - 物品数量<<用户数量
    - 物品之间的相似度比较静态，解耦了用户兴趣迁移这个问题
    - 物品对应的消费者数量较大，对于计算物品之间的相似度稀疏度是好过计算用户之间相似度的

  - 计算相似物品，然后再根据用户消费过、或者正在消费的物品为其推荐相似的，基本步骤如下：

    - 构建用户物品的关系矩阵，矩阵元素可以是用户的消费行为，或者消费后的评价，还可以是对消费行为的某种量化如时间、次数、费用等
    - 假如矩阵的行表示物品，列表示用户的话，那么就两两计算行向量之间的相似度，得到物品相似度矩阵，行和列都是物品
    - 产生推荐结果，根据场景不同，有两种形式：一是为某一个物品推荐相关物品，二是在个人首页产生类似”猜你喜欢“的推荐结果

  - 计算物品相似度

    - 常采用余弦相似度
    - 进一步改进包括：
      - 物品中心化。将矩阵中的分数减去物品分数的均值，这样做是去掉物品中铁杆粉丝群体的非理性因素
      - 用户中心化。把矩阵中的分数减去对应用户分数的均值，这样做在一定程度上保留了偏好，去掉了主观成分

  - 计算推荐结果

    - 第一种属于top-k推荐，形式上常常属于”猜你喜欢“这样的。
    - 第二种属于相关推荐，当用户访问一个物品的详情页面时，或者完成一个物品消费的结果面，直接获取这个物品的相似物品推荐，就是”看了又看“或者”买了又买“的推荐结果

    slope one算法：基于物品推荐、相似度计算可以实时更新、专门针对评分矩阵，不适用于行为矩阵，计算物品之间的距离，相似度的反面。

### 第9讲 【近邻计算】协同过滤中的相似度计算方法与那些

- 欧式距离，衡量两个点之间的距离，不适合布尔向量，度量的是绝对差异

- 余弦相似度，对绝对值大小不敏感，度量的是方向差异

- 皮尔逊相关度，实际上也是一种余弦相似度，不过先对向量做了中心化，结果范围在-1到1。

- 杰卡德相似度：是两个集合的交集元素个数在并集中所占的比例，适用于布尔向量。

  

### 第10讲 【矩阵分解】那些在Netflix Prize中大放异彩的推荐算法

![matrix](/home/mkyan/图片/matrix.jpg)

- 推荐系统中的经典问题

  - 评分预测：很经典，但不大众，评分数据在实际应用中很难收集
  - 行为预测：处处可见

- 近邻模型存在的问题：

  - 物品之间存在相关性，信息量并不随着向量维度的增加而线性增加
  - 矩阵元素稀疏，计算结果不稳定，增减一个向量维度，导致近邻结果差异很大的情况存在

  上述两个问题，在矩阵分解中可以得到解决。直观来说，就是把原来的大矩阵近似分解为两个小矩阵的乘积，在实际推荐计算时不再使用大矩阵，而是使用分解得到的两个小矩阵。

- 矩阵分解方法：
  - SVD算法（奇异值分解）
  - SVD+增加偏置信息：一个用户给一个物品的评分会由全局平均分、物品的评分偏置、用户评分的偏置、用户和物品之间的兴趣偏好组成。
  - SVD+增加历史行为：结合用户的隐式反馈行为和属性
  - SVD+考虑时间因素
    - 对评分按照时间加权，让久远的评分更趋近平均值
    - 对评分时间划分区间，不同的时间区间内分别学习出隐因子向量
    - 对特殊的期间，如节日、周末等训练对应的隐因子向量

### 第11讲 【矩阵分解】Facebook是怎么为十亿人互相推荐好友的

- 得到矩阵分解的损失函数后，要用到优化算法找到能使它最小的参数，优化方法有两个：

  - 随机梯度下降SGD
  - 交替最小二乘ALS

  在实际应用中，交替最小二乘更常用一些，Facebook所采用的就是此方法。

- 交替最小二乘原理 
  $$
  R_{m \times n} = P_{m \times k} \times Q^{T}_{n \times k}
  $$
  难就难在P和Q都是未知的，交替最小二乘通过迭代的方式解决这个难题：

  1. 初始化随机矩阵Ｑ中里面的元素值
  2. 把Q矩阵当做已知的，直接用线性代数的方法求得矩阵Ｐ
  3. 得到了矩阵Ｐ后，把P当做已知的，故技重施，回去求解矩阵Q
  4. 上面两个
  5. 过程交替进行，一直到误差可以接受为止

  交替最小二乘通常比随机梯度下降要更快地得到结果。

- 加权交替最小二乘：Weight-ALS 

  相比预测用户会打多少分，预测用户会不会去浏览更加有意义，而且用户浏览数据远远多于打分评价数据。也就是说，实际上推荐系统关注的是预测行为，行为就是隐式反馈。

  后台记录用户查看商品多少次，查看次数越多，代表越喜欢这个商品，也就是行为的次数是对行为的置信度反应，就是所谓的加权。

  - 如果用户对物品无隐式反馈，则认为评分是0
  - 如果用户对物品有至少一次隐式反馈，则任务评分是1，次数作为该评分的置信度

  目标函数变为：
  $$
  \min_{q^{* },p^{* } } \sum_{(u,i) \in \kappa }{c_{ui}(r_{ui} - p_{u}q_{i}^{T})^{2} + \lambda (||q_{i}||^{2} + ||p_{u}||^{2})}
  $$

  - 其中Cui就是置信度，在计算误差时考虑反馈次数，次数越多，就越可信。置信度一般等于
    $$
    c_{ui} = 1 + \alpha C
    $$
    C为次数，alpha是超参数，默认值取40

  - 那些没有反馈的缺失值可以通过采样得到：常采用negative sample，按照物品的热门程度采样。因为一个越热门的物品，用户越可能知道它的存在，在此情况下用户还没对它有反馈表明这可能就是真正的负样本。

- 推荐计算

  让用户和物品的隐因子向量两两相乘，计算点积可以得到推荐结果，但实际上复杂度还是很高，尤其对于用户数量和物品数量都巨大的应用。

  Facebook提出两个办法得到真正的推荐结果：

  - 利用专门设计的数据结构存储所有物品的隐因子向量，从而实现通过一个用户向量可以返回最相似的K个物品，开源实现：Faiss, NMSLIB
  - 第二种是拿着物品的隐因子向量先做聚类，然后逐一计算用户和每个聚类中心的推荐分数，从每个聚类中挑选少许几个物品作为最终推荐结果

### 第12讲 【矩阵分解】如果关注排序效果，那么这个模型可以帮到你

- point-wise和pair-wise
  - 针对单个用户对单个物品的偏好程度进行预测，得到结果后再排序的问题，称之为point-wise问题
  - 直接预测物品两两之间相对顺序的问题，叫做pair-wise
  
- 矩阵分解的不足
  
  - 矩阵分解都属于point-wise模型，不足之处在于，只能收集到正样本，没有负样本，虽然可以使用负样本采样来规避这个问题，为了排序而绕路也是事实。
  
- 直面问题，采用pair-wise来看待今天介绍的算法非常简单，但是在推荐系统中有很多的用途。尤其是面对的数据需要采样、需要有所变化时，加权采样本质上来说就是让权重影响采样概率。

  前面的几种加权采样算法，都是让采样概率和权重成正比，这意味着你的样本权重之间的关系要合理。

  那么，请思考另一个问题，如果你的样本权重有正有负，该如何加权采样呢？欢迎留言一起讨论。矩阵分解——贝叶斯个性化排序（BPR模型）

- 贝叶斯个性化排序
  - AUC替换均方根误差，关注相对排序，使用AUC指标
  - BPR模型主要有三点：
    - 样本构造方法：构造样本（用户、物品1、物品2、两个物品的相对顺序）
    - 模型目标函数：最大化交叉熵
    - 模型训练方法：梯度下降

### 第13讲 【模型融合】经典模型融合办法：线性模型和树模型的组合拳

- 推荐系统在技术实现上一般划分为三个阶段：挖掘、召回、排序
- 大部分挖掘工作都是离线进行的；因为物品太多了，所以需要召回；最后通过融合模型对召回的结果进行排序
- 融合方案之**逻辑回归+梯度提升树的组合**
- 特征工程+线性模型，是模型融合、CTR预估等必备技能
- FTRL，一种结合了L1正则化和L2正则的在线优化算法
- 梯度提升决策树 GBDT
- GBDT可以产生高阶特征组合，然后将新特征作为输入向量输给LR模型，输出最终的结果



### 第14讲 【特征融合】一网打尽协同过滤、矩阵分解和线性模型

- 在进行特征组合时可能遇到以下问题：两两组合导致特征维度灾难；组合后的特征不见得有效；组合后的特征样本非常稀疏。针对此问题，就有了新的算法模型：**因子分解机模型**，Factorization Machine,FM。
- Field-aware Factorization Machine,FFM
- 因子分解机也算是矩阵分解算法的一种，因为它的学习结果也是隐因子向量，也是用过隐因子向量的点积代替原来的单个权重参数。

### 第15讲 【模型融合】深度和宽度兼具的融合模型Wide and Deep

- 融合排序，最常见的就是CTR预估,CTR预估最常见做法就是广义线性模型，如LR，然后把重点放在特征工程上，特征工程让线性模型表现为一个很宽广（wide）的模型

- 深度模型的泛化性能强于线性模型，但其可解释性不够好

- 有效结合Wide模型和Deep模型才能最大限度发挥效果

- Wide&Deep模型

  ![recommend](/home/mkyan/图片/recommend.png)

  具体落地流程分为三大块：数据生成、模型训练、模型应用

  ![model](/home/mkyan/图片/model.png)

### 第16讲 【MAB问题】简单却有效的Bandit算法

![img](https://static001.geekbang.org/resource/image/11/4c/112709b33b1bfe5539eb3f1aa124f54c.jpg)

- 推荐其实也是选择，把推荐选择具体物品，上升到选择策略。每次选择一种策略，确定了策略后，再选择策略中的物品。
- 解决这个问题的方法就是Bandit算法，它是一类算法的统称。
- Bandit算法来源于赌博学中的多臂赌博机问题（MAB问题），只要是关于选择的问题，都可以简化成一个MAB问题。
- Bandit算法
  - 其思想是：看看选择会带来多少遗憾，遗憾越少越好
  - 在MAB问题中，用来量化选择好坏的指标就是累计遗憾
  - 常见的Bandit算法包括汤普森采样算法、UCB算法（Upper Confidence Bound,置信区间上界）、Epsilon贪婪算法



### 第17讲 【MAB问题】结合上下文信息的Bandit算法

- LinUCB算法

  它和传统UCB算法相比，最大的改进就是加入了特征信息，每次估算每个候选的置信区间，不再仅仅根据实验，而是根据特征信息来估算。

### 第18讲 【MAB算法】如何将Bandit算法与协同过滤结合使用

- 结合Bandit算法和传统的协同过滤来做推荐--COFIBA算法，不再是用户独立做决策，而是用户所在的群体共同决策推荐结果



### 第19讲 【深度学习】深度学习在推荐系统中的应用有哪些？

- 深度学习在推荐系统中的主要贡献在于特征表示学习和排序模型上。
- YouTube视频推荐

### 第20讲 【深度学习】用RNN构建个性化音乐播单

- Spotify使用RNN推荐音乐播单



### 第21讲 【其他应用算法】构建一个科学的排行榜体系

- 为什么需要排行榜？

  - 可以作为解决新用户冷启动问题的推荐策略
  - 可以作为老用户的兴趣发现方式
  - 排行榜本身就是一个降级的推荐系统

- 排行榜算法

  最简单的排行榜，就是直接统计某种指标，按照大小去排序。此方法存在如下问题：

  - 非常容易被攻击，也就是被刷榜
  - 马太效应已知存在，除非强制替换，否则一些破纪录的物品会一直占据在榜单中
  - 不能反映出排行榜随着时间的变化，这一点和马太效应有关

  针对以上弊端，设计应对方法：

  - 考虑时间因素
  - 考虑三种投票
  - 考虑好评的平均程度



### 第22讲 【其他应用算法】使用的加权采样算法

- 加权采样有两种情况：
  - 一种是能够已知全部样本的个数，这需要遍历整个样本。
  - 另一种是不知道总量样本是多大，或者总量很大，以至于你不愿意全部遍历之后再输出采样结果，这样的数据就是数据流，对应的就是流采样。



### 第23讲 【其他应用算法】推荐候选池的去重策略

- 在推荐系统中，有一个刚需就是去重：主要有两个地方
  - 内容源去重：对内容做重复检测，直观思路是分词，提取关键词，再两两计算词向量之间的距离，小于一定阈值后判定为重复，对于海量内容来说，有点灾难
  - 不重复给用户推荐：内容阅读类推荐场景下，给用户推荐的内容不要重复，推荐过的内容就不再出现在推荐候选集中
- 内容重复检测算法：Simhash
  - 核心思想：为每个内容生成一个整数表示的指纹，然后用这个指纹去做重复或者相似的检测。
- 防止内容被重复推荐：Bloomfilter（布隆过滤器）	



### 第XX讲 【开源工具】和推荐系统有关的开源工具及框架介绍

- 内容分析

  基于内容的推荐，主要工作集中在处理文本，或者把数据视为文本去处理。文本分析相关的工作就是将非结构化的文本转换为结构化。主要有：

  - 主题模型
  - 词嵌入
  - 文本分类

  相应的开源工具有：

  ![img](https://static001.geekbang.org/resource/image/22/e2/22a0bbe4cbb5ce41d045aedd1e2128e2.png)

- 协同过滤和矩阵分解

  基于用户、基于物品的协同过滤，矩阵分解，都依赖对用户物品关系矩阵的利用，常常涉及以下工作：

  - KNN相似度计算
  -  SVD矩阵分解
  - ALS矩阵分解
  - BPR矩阵分解
  - 低维稠密向量近邻搜索

​	相应的开源工具有:

![img](https://static001.geekbang.org/resource/image/c2/ef/c2c9d45939566395b3936d25a422e4ef.png)

- 模型融合

  模型融合这部分有线性模型和梯度提升树模型。

  ![img](https://static001.geekbang.org/resource/image/88/59/886d6963721480a73a7f6a16ae77f759.png)

- 完整推荐系统

  完整的推荐系统：包含推荐算法实现、存储、接口。

  ![img](https://static001.geekbang.org/resource/image/91/5e/910ca0b2f233ce2c9c855a21ae71815e.png)



### 第X讲 【产品篇】推荐系统在互联网产品商业链条中的地位

- 所谓信息经济其实就是注意力经济，而推荐系统就是留住注意力的重要手段。
- 用户产生行为就是付出注意力的表现。
- 注意力是一种决策可能性。
- 注意力有个特点：总量有限，随着信息越来越丰富，注意力越来越稀缺。
- 推荐系统是数据贪婪型

### 第X讲【产品篇】说说信息流的前世今生

- 信息流就是feed，包括社交动态信息流、也有图文咨询信息流、短视频信息流等
- 在今天，最厉害的注意力存储器就是信息流，尤其是个性化信息流，也叫兴趣feed，是推荐系统的一种
- 完整的信息流产品需要配套设施如：
  - 内容源：质量、多样性、数量
  - 广告系统：商业社会永远是逐利的

### 第X讲 【产品篇】组建推荐团队及工程师的学习路径

- 工程师的个人学习和成长：
  - 三个核心素质要求：
    - 有较强的工程能力，能快速交付高效率少bug的算法实现
    - 有较强的理论基础，能看懂最新论文
    - 有很好的可视化思维，能将不直观的数据规律直观地呈现出来
  - 实现整个推荐系统的路径不可复制，这个实现路径就是工程，工程能力决定了推荐系统的上线，如何提高工程能力，无他，就是反复刻意练习
  - 爱动手、爱思考、爱阅读、爱总结
  - 理论基础：高等数学、概率论、线性代数、信息论
  - 可视化工具：Python中的Matplotlib
  - 此外的加分项：学习能力强、沟通能力强、表达能力强

### 第X讲 推荐系统的参考阅读

